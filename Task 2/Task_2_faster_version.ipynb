{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62ca69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "import nltk\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer()\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm # monitoring progress\n",
    "\n",
    "import time\n",
    "from joblib import Parallel, delayed # parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84d12a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Release date</th>\n",
       "      <th>End date</th>\n",
       "      <th>Members</th>\n",
       "      <th>Score</th>\n",
       "      <th>Users</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Related</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04 00:00:00</td>\n",
       "      <td>2676639</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1622384</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[\"After a horrific alchemy experiment goes wro...</td>\n",
       "      <td>['Adaptation: Fullmetal Alchemist', 'Alternati...</td>\n",
       "      <td>['Elric, Edward', 'Elric, Alphonse', 'Mustang,...</td>\n",
       "      <td>['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...</td>\n",
       "      <td>[['Cook, Justin', 'Producer'], ['Yonai, Norito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gintama: The Final</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>-</td>\n",
       "      <td>79486</td>\n",
       "      <td>9.00</td>\n",
       "      <td>29979</td>\n",
       "      <td>10</td>\n",
       "      <td>1924</td>\n",
       "      <td>['New ', &lt;i&gt;Gintama&lt;/i&gt;, ' movie.']</td>\n",
       "      <td>['Adaptation: Gintama', 'Prequel: Gintama.: Sh...</td>\n",
       "      <td>['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...</td>\n",
       "      <td>['Sugita, Tomokazu', 'Ishida, Akira', 'Hino, S...</td>\n",
       "      <td>[['Fujita, Youichi', 'Director'], ['Miyawaki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gintama.</td>\n",
       "      <td>TV</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>2017-03-27 00:00:00</td>\n",
       "      <td>246290</td>\n",
       "      <td>8.98</td>\n",
       "      <td>108581</td>\n",
       "      <td>11</td>\n",
       "      <td>726</td>\n",
       "      <td>[\"After joining the resistance against the bak...</td>\n",
       "      <td>['Adaptation: Gintama', 'Prequel: Gintama°', '...</td>\n",
       "      <td>['Sakata, Gintoki', 'Kagura', 'Katsura, Kotaro...</td>\n",
       "      <td>['Sugita, Tomokazu', 'Kugimiya, Rie', 'Ishida,...</td>\n",
       "      <td>[['Fujita, Youichi', 'Director'], ['Miyawaki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-gatsu no Lion 2nd Season</td>\n",
       "      <td>TV</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>2018-03-31 00:00:00</td>\n",
       "      <td>324393</td>\n",
       "      <td>8.97</td>\n",
       "      <td>155163</td>\n",
       "      <td>12</td>\n",
       "      <td>529</td>\n",
       "      <td>['Now in his second year of high school, Rei K...</td>\n",
       "      <td>['Adaptation: 3-gatsu no Lion', 'Prequel: 3-ga...</td>\n",
       "      <td>['Kiriyama, Rei', 'Kawamoto, Hinata', 'Kawamot...</td>\n",
       "      <td>['Kawanishi, Kengo', 'Hanazawa, Kana', 'Kayano...</td>\n",
       "      <td>[['Shinbou, Akiyuki', 'Director, Series Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>-</td>\n",
       "      <td>1780070</td>\n",
       "      <td>8.97</td>\n",
       "      <td>1208990</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>['As a wild youth, elementary school student S...</td>\n",
       "      <td>['Adaptation: Koe no Katachi', 'Other: Koe no ...</td>\n",
       "      <td>['Nishimiya, Shouko', 'Ishida, Shouya', 'Nishi...</td>\n",
       "      <td>['Hayami, Saori', 'Irino, Miyu', 'Yuuki, Aoi',...</td>\n",
       "      <td>[['Senami, Riri', 'Assistant Producer'], ['Yam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title   Type  Episodes Release date  \\\n",
       "0  Fullmetal Alchemist: Brotherhood     TV        64   2009-04-05   \n",
       "1                Gintama: The Final  Movie         1   2021-01-08   \n",
       "2                          Gintama.     TV        12   2017-01-09   \n",
       "3        3-gatsu no Lion 2nd Season     TV        22   2017-10-14   \n",
       "4                    Koe no Katachi  Movie         1   2016-09-17   \n",
       "\n",
       "              End date  Members  Score    Users  Rank  Popularity  \\\n",
       "0  2010-07-04 00:00:00  2676639   9.16  1622384     1           3   \n",
       "1                    -    79486   9.00    29979    10        1924   \n",
       "2  2017-03-27 00:00:00   246290   8.98   108581    11         726   \n",
       "3  2018-03-31 00:00:00   324393   8.97   155163    12         529   \n",
       "4                    -  1780070   8.97  1208990    13          23   \n",
       "\n",
       "                                         Description  \\\n",
       "0  [\"After a horrific alchemy experiment goes wro...   \n",
       "1                ['New ', <i>Gintama</i>, ' movie.']   \n",
       "2  [\"After joining the resistance against the bak...   \n",
       "3  ['Now in his second year of high school, Rei K...   \n",
       "4  ['As a wild youth, elementary school student S...   \n",
       "\n",
       "                                             Related  \\\n",
       "0  ['Adaptation: Fullmetal Alchemist', 'Alternati...   \n",
       "1  ['Adaptation: Gintama', 'Prequel: Gintama.: Sh...   \n",
       "2  ['Adaptation: Gintama', 'Prequel: Gintama°', '...   \n",
       "3  ['Adaptation: 3-gatsu no Lion', 'Prequel: 3-ga...   \n",
       "4  ['Adaptation: Koe no Katachi', 'Other: Koe no ...   \n",
       "\n",
       "                                          Characters  \\\n",
       "0  ['Elric, Edward', 'Elric, Alphonse', 'Mustang,...   \n",
       "1  ['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...   \n",
       "2  ['Sakata, Gintoki', 'Kagura', 'Katsura, Kotaro...   \n",
       "3  ['Kiriyama, Rei', 'Kawamoto, Hinata', 'Kawamot...   \n",
       "4  ['Nishimiya, Shouko', 'Ishida, Shouya', 'Nishi...   \n",
       "\n",
       "                                              Voices  \\\n",
       "0  ['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...   \n",
       "1  ['Sugita, Tomokazu', 'Ishida, Akira', 'Hino, S...   \n",
       "2  ['Sugita, Tomokazu', 'Kugimiya, Rie', 'Ishida,...   \n",
       "3  ['Kawanishi, Kengo', 'Hanazawa, Kana', 'Kayano...   \n",
       "4  ['Hayami, Saori', 'Irino, Miyu', 'Yuuki, Aoi',...   \n",
       "\n",
       "                                               Staff  \n",
       "0  [['Cook, Justin', 'Producer'], ['Yonai, Norito...  \n",
       "1  [['Fujita, Youichi', 'Director'], ['Miyawaki, ...  \n",
       "2  [['Fujita, Youichi', 'Director'], ['Miyawaki, ...  \n",
       "3  [['Shinbou, Akiyuki', 'Director, Series Compos...  \n",
       "4  [['Senami, Riri', 'Assistant Producer'], ['Yam...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('file.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a10ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19053, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104a5a77",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cdc8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(description):\n",
    "    # input: string\n",
    "    # output: list of tokenized words included in the string\n",
    "        \n",
    "    low_descr = str.lower(description)\n",
    "    \n",
    "    # We tokenize the description and remove puncuation\n",
    "    tok_descr = tokenizer.tokenize(low_descr)\n",
    "    # Alternative way: first tokenize then remove punctuation\n",
    "    # tok_descr = nltk.word_tokenize(low_descr)\n",
    "    # nltk.download(\"punkt\")\n",
    "    # no_pun_descr = [word for word in tok_descr if word.isalnum()]\n",
    "    \n",
    "    return tok_descr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66babe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(tok_descr):\n",
    "    # input: list of tokenized words included in the string\n",
    "    # output: list of cleaned words included in the string\n",
    "    \n",
    "    # We remove stopwords from tokenized description\n",
    "    no_stop_descr = [word for word in tok_descr if not word in stopwords.words('english')]\n",
    "    \n",
    "    # We carry out stemming\n",
    "    stem_descr = [ps.stem(i) for i in no_stop_descr]\n",
    "    \n",
    "    # We remove isolated characters\n",
    "    final_descr = [i for i in stem_descr if len(i) > 1]\n",
    "        \n",
    "    return final_descr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7434d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_fast(tok_descr):\n",
    "    # Please note: by using intersection of sets instead of list comprehension we lose repeated words within the same description\n",
    "    \n",
    "    # input: list of tokenized words included in the string\n",
    "    # output: list of cleaned words included in the string\n",
    "    \n",
    "    # We remove stopwords from tokenized description\n",
    "    no_stop_descr = list(set(tok_descr) - (set(tok_descr) & set(stopwords.words('english'))))\n",
    "    \n",
    "    # We carry out stemming\n",
    "    stem_descr = [ps.stem(i) for i in no_stop_descr]\n",
    "    \n",
    "    # We remove isolated characters\n",
    "    final_descr = [i for i in stem_descr if len(i) > 1]\n",
    "        \n",
    "    return list(set(final_descr))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0567f5",
   "metadata": {},
   "source": [
    "#### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adafdadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"After a horrific alchemy experiment goes wrong in the Elric household, brothers Edward and Alphonse are left in a catastrophic new reality. Ignoring the alchemical principle banning human transmutation, the boys attempted to bring their recently deceased mother back to life. Instead, they suffered brutal personal loss: Alphonse\\'s body disintegrated while Edward lost a leg and then sacrificed an arm to keep Alphonse\\'s soul in the physical realm by binding it to a hulking suit of armor.\", \\'\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'\\\\r\\\\nThe brothers are rescued by their neighbor Pinako Rockbell and her granddaughter Winry. Known as a bio-mechanical engineering prodigy, Winry creates prosthetic limbs for Edward by utilizing \"automail,\" a tough, versatile metal used in robots and combat armor. After years of training, the Elric brothers set off on a quest to restore their bodies by locating the Philosopher\\\\\\'s Stone—a powerful gem that allows an alchemist to defy the traditional laws of Equivalent Exchange.\\', \\'\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'\\\\r\\\\nAs Edward becomes an infamous alchemist and gains the nickname \"Fullmetal,\" the boys\\\\\\' journey embroils them in a growing conspiracy that threatens the fate of the world.\\', \\'\\\\n\\', \\'\\\\n\\', \\'\\\\n\\', \\'\\\\r\\\\n[Written by MAL Rewrite]\\']'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdc73db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horrif',\n",
       " 'alchemi',\n",
       " 'experi',\n",
       " 'goe',\n",
       " 'wrong',\n",
       " 'elric',\n",
       " 'household',\n",
       " 'brother',\n",
       " 'edward',\n",
       " 'alphons',\n",
       " 'left',\n",
       " 'catastroph',\n",
       " 'new',\n",
       " 'realiti',\n",
       " 'ignor',\n",
       " 'alchem',\n",
       " 'principl',\n",
       " 'ban',\n",
       " 'human',\n",
       " 'transmut',\n",
       " 'boy',\n",
       " 'attempt',\n",
       " 'bring',\n",
       " 'recent',\n",
       " 'deceas',\n",
       " 'mother',\n",
       " 'back',\n",
       " 'life',\n",
       " 'instead',\n",
       " 'suffer',\n",
       " 'brutal',\n",
       " 'person',\n",
       " 'loss',\n",
       " 'alphons',\n",
       " 'bodi',\n",
       " 'disintegr',\n",
       " 'edward',\n",
       " 'lost',\n",
       " 'leg',\n",
       " 'sacrif',\n",
       " 'arm',\n",
       " 'keep',\n",
       " 'alphons',\n",
       " 'soul',\n",
       " 'physic',\n",
       " 'realm',\n",
       " 'bind',\n",
       " 'hulk',\n",
       " 'suit',\n",
       " 'armor',\n",
       " 'nthe',\n",
       " 'brother',\n",
       " 'rescu',\n",
       " 'neighbor',\n",
       " 'pinako',\n",
       " 'rockbel',\n",
       " 'granddaught',\n",
       " 'winri',\n",
       " 'known',\n",
       " 'bio',\n",
       " 'mechan',\n",
       " 'engin',\n",
       " 'prodigi',\n",
       " 'winri',\n",
       " 'creat',\n",
       " 'prosthet',\n",
       " 'limb',\n",
       " 'edward',\n",
       " 'util',\n",
       " 'automail',\n",
       " 'tough',\n",
       " 'versatil',\n",
       " 'metal',\n",
       " 'use',\n",
       " 'robot',\n",
       " 'combat',\n",
       " 'armor',\n",
       " 'year',\n",
       " 'train',\n",
       " 'elric',\n",
       " 'brother',\n",
       " 'set',\n",
       " 'quest',\n",
       " 'restor',\n",
       " 'bodi',\n",
       " 'locat',\n",
       " 'philosoph',\n",
       " 'stone',\n",
       " 'power',\n",
       " 'gem',\n",
       " 'allow',\n",
       " 'alchemist',\n",
       " 'defi',\n",
       " 'tradit',\n",
       " 'law',\n",
       " 'equival',\n",
       " 'exchang',\n",
       " 'na',\n",
       " 'edward',\n",
       " 'becom',\n",
       " 'infam',\n",
       " 'alchemist',\n",
       " 'gain',\n",
       " 'nicknam',\n",
       " 'fullmet',\n",
       " 'boy',\n",
       " 'journey',\n",
       " 'embroil',\n",
       " 'grow',\n",
       " 'conspiraci',\n",
       " 'threaten',\n",
       " 'fate',\n",
       " 'world',\n",
       " 'written',\n",
       " 'mal',\n",
       " 'rewrit']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(tokenize(dataset['Description'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18de1a7",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "\n",
    "- the first dictionary <code>word_2_id</code> maps word to word identification integer\n",
    "\n",
    "- the inverted index dictionary <code>id_2_anime</code> maps word identification integer to list of indexes (main dataset indexes) of anime whose cleaned description contains the word identified by the integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fc4d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionaries(dataset):\n",
    "    # input: anime_df dataframe\n",
    "    # output 1: the dictionary word_2_id maps word to word identification integer  \n",
    "    # output 2: the inverted index dictionary id_2_anime maps word identification integer to list of indexes (main dataset indexes) of anime\n",
    "\n",
    "    word_2_id = defaultdict()\n",
    "    word_2_id['a'] = 0\n",
    "\n",
    "    id_2_anime = defaultdict()\n",
    "        \n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        \n",
    "        final_list = clean_fast(tokenize(dataset['Description'][i]))    \n",
    "        \n",
    "        if final_list == []:\n",
    "            \n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "\n",
    "            for j in final_list:\n",
    "\n",
    "                if j not in word_2_id.keys():\n",
    "\n",
    "                    word_2_id[j] = word_2_id[list(word_2_id.keys())[-1]] + 1\n",
    "\n",
    "                    id_2_anime[word_2_id[j]] = [i]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    id_2_anime[word_2_id[j]].append(i)\n",
    "    \n",
    "    # We save dictionaries as pkl\n",
    "    word_2_id_file = open(\"word2id.pkl\", \"wb\")\n",
    "    pickle.dump(word_2_id, word_2_id_file)\n",
    "    word_2_id_file.close()\n",
    "    \n",
    "    id_2_anime_file = open(\"id2anime.pkl\", \"wb\")\n",
    "    pickle.dump(id_2_anime, id_2_anime_file)\n",
    "    id_2_anime_file.close()\n",
    "\n",
    "    return word_2_id, id_2_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67711e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 19053/19053 [00:21<00:00, 875.86it/s]\n"
     ]
    }
   ],
   "source": [
    "word_2_id0, id_2_anime0 = dictionaries(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47fac928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39599"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_2_id0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a9ed0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_2_anime0) == len(word_2_id0) - 1 # -1 inizialization value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d09ddc",
   "metadata": {},
   "source": [
    "### Extended dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6659f30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5978 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 17984 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 19053 out of 19053 | elapsed:    2.5s finished\n"
     ]
    }
   ],
   "source": [
    "dataset[\"tok_description\"] = Parallel(n_jobs=-1, verbose=3)(delayed(tokenize)(i) for i in dataset[\"Description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdc2d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 19053/19053 [00:00<00:00, 41421.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "tqdm.pandas()\n",
    "dataset['tok_description'] = dataset.progress_apply(lambda j: tokenize(j['Description']),axis=1)\n",
    "#end = time.time()\n",
    "#print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbc83b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 19053/19053 [03:26<00:00, 92.21it/s]\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "tqdm.pandas()\n",
    "dataset['clean_description'] = dataset.progress_apply(lambda j: clean(j['tok_description']),axis=1)\n",
    "#end = time.time()\n",
    "#print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef252cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv (r'C:\\Users\\anton\\Desktop\\ADM\\Homework3\\ext_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0ccb7d",
   "metadata": {},
   "source": [
    "faster cleaning (but we remove repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8f234d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 19053/19053 [00:14<00:00, 1274.63it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "dataset['clfast_description'] = dataset.progress_apply(lambda j: clean_fast(j['tok_description']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a438b",
   "metadata": {},
   "source": [
    "### Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aee9115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_engine(query):\n",
    "    # input: query as string\n",
    "    # output: list of indexes (anime_df dataframe) of anime whose description contains all the words in the query\n",
    "    \n",
    "    # We load dictionaries\n",
    "    word_2_id_file = open(\"word2id.pkl\", \"rb\")\n",
    "    word_2_id = pickle.load(word_2_id_file)\n",
    "    word_2_id_file.close()\n",
    "    id_2_anime_file = open(\"id2anime.pkl\", \"rb\")\n",
    "    id_2_anime = pickle.load(id_2_anime_file)\n",
    "    id_2_anime_file.close()\n",
    "    \n",
    "    # We filter query (apply tokenizeandclean function and remove duplicates)\n",
    "    cleaned_query = list(set(clean(tokenize(query))))\n",
    "        \n",
    "    listoflists = []\n",
    "    \n",
    "    for i in range(len(cleaned_query)):\n",
    "        listoflists.append(set(id_2_anime[word_2_id[cleaned_query[i]]]))\n",
    "        \n",
    "    anime_intersection = list(set.intersection(*listoflists))\n",
    "    \n",
    "    return sorted(anime_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4deddcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6185, 11167, 17967, 18503]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = search_engine(\"saiyan race\")\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb085f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dragon Ball Kai</td>\n",
       "      <td>[\"Five years after the events of Dragon Ball, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dragon Ball Z Special 1: Tatta Hitori no Saish...</td>\n",
       "      <td>[\"Bardock, Son Goku's father, is a low-ranking...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dragon Ball Z</td>\n",
       "      <td>[\"Five years after winning the World Martial A...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dragon Ball Super: Broly</td>\n",
       "      <td>[\"Forty-one years ago on Planet Vegeta, home o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                    Dragon Ball Kai   \n",
       "1  Dragon Ball Z Special 1: Tatta Hitori no Saish...   \n",
       "2                                      Dragon Ball Z   \n",
       "3                           Dragon Ball Super: Broly   \n",
       "\n",
       "                                         Description Url  \n",
       "0  [\"Five years after the events of Dragon Ball, ...      \n",
       "1  [\"Bardock, Son Goku's father, is a low-ranking...      \n",
       "2  [\"Five years after winning the World Martial A...      \n",
       "3  [\"Forty-one years ago on Planet Vegeta, home o...      "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfq = dataset.iloc[q, [0, 10]]\n",
    "dfq.reset_index(drop=True, inplace=True)\n",
    "dfq['Url'] = ''\n",
    "dfq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
