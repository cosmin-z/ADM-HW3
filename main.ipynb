{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import lxml\n",
    "import csv\n",
    "import psutil\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constante variaible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_txt = \"https.txt\"\n",
    "folder = 'Task 1.2/dataset'\n",
    "folder2 = 'Task 1.3/anime_tsv'\n",
    "headers = {\n",
    "    'user-agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36\",\n",
    "    'accept': \"image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8\",\n",
    "    'referer': \"https://myanimelist.net/\"\n",
    "} \n",
    "save_path = 'simplePath'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "reg = r'href=\\\"https://[\\w\\W]*\" id'\n",
    "htt = list()\n",
    "for i in range(400):\n",
    "    cnt = requests.get(\"https://myanimelist.net/topanime.php?limit=\"+str(i*50))\n",
    "    soup = BeautifulSoup(cnt.content, features=\"lxml\")\n",
    "    links = soup.find_all('h3')\n",
    "    for l in range(len(links)-3):\n",
    "        li = links[l].find('a')\n",
    "        m = re.findall(reg, str(li))\n",
    "        s = m[0][6:][:-4]+'\\n'\n",
    "        htt.append(s)\n",
    "f = open(\"urls_txt\", 'w')\n",
    "for i in htt:\n",
    "    f.write(i)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def htmls_by_urls(urls_txt, folder):\n",
    "     # urls_txt: string 'https.txt' from previous task\n",
    "    # folder: string; eg '/Users/anton/Desktop/ADM/Homework3/html'\n",
    "    \n",
    "    with open(urls_txt, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    # list of urls\n",
    "    list_txt = [line.strip() for line in lines]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while i < len(list_txt):\n",
    "        url = list_txt[i]\n",
    "        # folder where we save html\n",
    "        al_folder = '{}/page_{}/{}.html'.format(folder, i//50 +1, i+1)\n",
    "        # download html\n",
    "        html = requests.get(url, headers)\n",
    "        if(html.status_code != 200) : \n",
    "            time.sleep(120)\n",
    "            print('error', html.status_code)\n",
    "        else:\n",
    "            i += 1\n",
    "            with open(al_folder, 'w', encoding='utf-8') as g:\n",
    "                g.write(html.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error 403\n",
      "error 403\n",
      "error 403\n",
      "error 403\n"
     ]
    }
   ],
   "source": [
    "htmls_by_urls(urls_txt, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19053\n"
     ]
    }
   ],
   "source": [
    "arr = os.listdir(folder)\n",
    "alarr = list()\n",
    "for y in arr:\n",
    "    if \"rar\" in y:\n",
    "        continue\n",
    "    fiarr = os.listdir(folder+'/'+y)\n",
    "    if '.ipynb_checkpoints' in fiarr:\n",
    "        fiarr.remove('.ipynb_checkpoints')\n",
    "    for i in range(len(fiarr)):\n",
    "        fiarr[i] = y+'/'+fiarr[i]\n",
    "    alarr.extend(fiarr)\n",
    "print(len(alarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1.2/dataset/page_341/17050.html 13499\n",
      "Task 1.2/dataset/page_350/17500.html 13999\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0eeec56c7599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#print(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0manimeTitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'strong'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<!--\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_comment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/html/parser.py\u001b[0m in \u001b[0;36mparse_endtag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_cdata_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgtpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mhandle_endtag\u001b[0;34m(self, name, check_already_closed)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malready_closed_empty_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reg1 = r'\\n[\\w\\W]*to'\n",
    "reg2 = r'to[\\w\\W]*\\n'\n",
    "trfile = 'file.csv'\n",
    "animeTitle = []\n",
    "animeTypes = []\n",
    "animeNumEpisode = []\n",
    "releaseDate = []\n",
    "endDate = []\n",
    "animeNumMembers = []\n",
    "animeScore = []\n",
    "animeUsers = []\n",
    "animeRank = []\n",
    "animePopularity = []\n",
    "animeDescription = []\n",
    "animeRelated = []\n",
    "animeCharacters = []\n",
    "animeVoices = []\n",
    "animeStaff = [] \n",
    "df = pd.DataFrame(\n",
    "[animeTitle, animeTypes, animeNumEpisode, releaseDate, endDate, animeNumMembers, animeScore, animeUsers, animeRank, animePopularity, animeDescription, animeRelated, animeCharacters, animeVoices, animeStaff], \n",
    "index=['Title', 'Type', 'Episodes','Release date', 'End date', 'Members', 'Score', 'Users', 'Rank', 'Popularity', 'Description', 'Related', 'Characters', 'Voices', 'Staff']\n",
    ").T\n",
    "bs = 9\n",
    "for fiName in range(len(alarr)):\n",
    "    # anime titles\n",
    "    path = folder+'/'+alarr[fiName]\n",
    "    #print(path)\n",
    "    file = codecs.open(path, \"r\", \"utf-8\")\n",
    "    soup = BeautifulSoup(file, 'html.parser')\n",
    "    animeTitle.append(soup.find_all('strong')[0].contents[0])\n",
    "    \n",
    "    # left sied of the html------------------------------------------------------------\n",
    "    divs = soup.find_all(\"div\", {\"class\": \"spaceit_pad\"})\n",
    "    for div in divs:\n",
    "        spans = div.find_all(\"span\")\n",
    "        for span in spans:\n",
    "            # anime types\n",
    "            if span.contents[0] == 'Type:':\n",
    "                tr = div.find_all('a')\n",
    "                if len(tr) ==0:\n",
    "                    animeTypes.append(div.contents[2][2:])\n",
    "                else:\n",
    "                    animeTypes.append(div.find_all('a')[0].contents[0])\n",
    "            # anime number of episodes\n",
    "            if span.contents[0] == 'Episodes:':\n",
    "                try :\n",
    "                    animeNumEpisode.append(int(div.contents[2]))\n",
    "                except:\n",
    "                    animeNumEpisode.append(0)\n",
    "            # anime release and end dates\n",
    "            if span.contents[0] == 'Aired:':\n",
    "                if 'Not available' in div.contents[2]:\n",
    "                    releaseDate.append('?')\n",
    "                    endDate.append('?')\n",
    "                elif 'to' in div.contents[2]:\n",
    "                    if \"?\" in re.findall(reg2, str(div.contents[2]))[0][3:-1]:\n",
    "                        endDate.append(\"?\")\n",
    "                    else:\n",
    "                        #print(re.findall(reg2, str(div.contents[2]))[0][3:-1])\n",
    "                        releaseDate.append(pd.to_datetime(re.findall(reg1, str(div.contents[2]))[0][2:-3]))\n",
    "                        endDate.append(pd.to_datetime(re.findall(reg2, str(div.contents[2]))[0][3:-1]))\n",
    "                else:\n",
    "                    releaseDate.append(pd.to_datetime(div.contents[2][2:-2]))\n",
    "                    endDate.append('-')\n",
    "                    \n",
    "    # middle side of the html------------------------------------------------------------\n",
    "    divs = soup.find_all(\"div\", {\"class\": \"stats-block po-r clearfix\"})\n",
    "    for div in divs:\n",
    "        # anime number of members\n",
    "        members = div.find_all(\"span\", {\"class\": \"numbers members\"})\n",
    "        animeNumMembers.append(int(members[0].contents[1].contents[0].replace(',', '')))\n",
    "        # anime score\n",
    "        score = div.find_all(\"div\", {\"class\": \"score-label score-\"+str(bs)})\n",
    "        while len(score) == 0:\n",
    "            bs -= 1\n",
    "            score = div.find_all(\"div\", {\"class\": \"score-label score-\"+str(bs)})\n",
    "            if bs == -1:\n",
    "                bs = 10\n",
    "                score = div.find_all(\"div\", {\"class\": \"score-label score-na\"})\n",
    "        try:        \n",
    "            animeScore.append(float(score[0].contents[0]))\n",
    "            # anime number of users\n",
    "            users = div.find_all(\"div\", {\"class\": \"fl-l score\"})\n",
    "            animeUsers.append(int(users[0]['data-user'][:-6].replace(',', '')))\n",
    "        except:\n",
    "            animeScore.append(None)\n",
    "            animeUsers.append(0)\n",
    "\n",
    "        # anime rank\n",
    "        rank = div.find_all(\"span\", {\"class\": \"numbers ranked\"})\n",
    "        try:\n",
    "            animeRank.append(int(rank[0].contents[1].contents[0][1:]))\n",
    "        except:\n",
    "            animeRank.append(-1)\n",
    "        # anime popularity\n",
    "        popularity = div.find_all(\"span\", {\"class\": \"numbers popularity\"})\n",
    "        animePopularity.append(int(popularity[0].contents[1].contents[0][1:]))\n",
    "        \n",
    "    # anime description\n",
    "    description = soup.find_all(\"p\", {\"itemprop\": \"description\"})\n",
    "    for br in description[0].find_all(\"br\"):\n",
    "        br.replace_with(\"\\n\")\n",
    "    animeDescription.append(description[0].contents)\n",
    "    \n",
    "    # related animes \n",
    "    related = soup.find_all(\"table\", {\"class\": \"anime_detail_related_anime\"})\n",
    "    x = []\n",
    "    y = []\n",
    "    for tr in related:\n",
    "        td = tr.find_all(\"td\")\n",
    "        for i in range(0, len(td), 2):\n",
    "            x.append(td[i].contents[0])\n",
    "            try:\n",
    "                t = td[i+1].find_all(\"a\")\n",
    "                y.append(t[0].contents[0])\n",
    "            except:\n",
    "                y.append('NA')\n",
    "            \n",
    "        animeRelated.append('\\n'.join([f'{x} {y}' for x, y in dict(zip(x, y)).items()]).split('\\n'))\n",
    "    try:    \n",
    "        # anime characters and voices\n",
    "        characters = soup.find_all(\"div\", {\"class\": \"detail-characters-list clearfix\"})\n",
    "        chars = characters[0].find_all(\"h3\", {\"class\": \"h3_characters_voice_actors\"})\n",
    "        x = []\n",
    "        y = []\n",
    "        voices = characters[0].find_all(\"td\", {\"class\": \"va-t ar pl4 pr4\"})\n",
    "        for i in chars:\n",
    "            x.append(i.contents[0].contents[0])\n",
    "        for i in voices:\n",
    "            y.append(i.contents[1].contents[0])\n",
    "        animeCharacters.append(x)\n",
    "        animeVoices.append(y)\n",
    "    except:\n",
    "        animeCharacters.append(\"NA\")\n",
    "        animeVoices.append(\"NA\")\n",
    "    \n",
    "    # anime staff\n",
    "    try:\n",
    "        staff = soup.find_all(\"div\", {\"class\": \"detail-characters-list clearfix\"})\n",
    "        staff = staff[1].find_all(\"td\")\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(1, len(staff), 2):\n",
    "            x.append(staff[i].contents[1].contents[0])\n",
    "            y.append(staff[i].find_all(\"small\")[0].contents[0])\n",
    "        animeStaff.append([list(i) for i in list(zip(x,y))])\n",
    "    except:\n",
    "        animeStaff.append(\"NA\")\n",
    "    # Following lines are made to save memory by storing the current info in a pd instead of the array    \n",
    "    if ((fiName+1)%500) == 0:\n",
    "        print(path,fiName)\n",
    "        dftr = pd.DataFrame(\n",
    "        [animeTitle.copy(), animeTypes.copy(), animeNumEpisode.copy(), releaseDate.copy(), endDate.copy(), animeNumMembers.copy(), animeScore.copy(), animeUsers.copy(), animeRank.copy(), animePopularity.copy(), animeDescription.copy(), animeRelated.copy(), animeCharacters.copy(), animeVoices.copy(), animeStaff], \n",
    "        index=['Title', 'Type', 'Episodes','Release date', 'End date', 'Members', 'Score', 'Users', 'Rank', 'Popularity', 'Description', 'Related', 'Characters', 'Voices', 'Staff']\n",
    "        ).T\n",
    "\n",
    "        df = pd.concat([df, dftr])\n",
    "        df.to_csv(trfile, index=False)\n",
    "        del df, dftr\n",
    "        animeTitle = []\n",
    "        animeTypes = []\n",
    "        animeNumEpisode = []\n",
    "        releaseDate = []\n",
    "        endDate = []\n",
    "        animeNumMembers = []\n",
    "        animeScore = []\n",
    "        animeUsers = []\n",
    "        animeRank = []\n",
    "        animePopularity = []\n",
    "        animeDescription = []\n",
    "        animeRelated = []\n",
    "        animeCharacters = []\n",
    "        animeVoices = []\n",
    "        animeStaff = [] \n",
    "        df = pd.read_csv(trfile)\n",
    "        os.remove(trfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr = pd.DataFrame(\n",
    "[animeTitle, animeTypes, animeNumEpisode, releaseDate, endDate, animeNumMembers, animeScore, animeUsers, animeRank, animePopularity, animeDescription, animeRelated, animeCharacters, animeVoices, animeStaff], \n",
    "index=['Title', 'Type', 'Episodes','Release date', 'End date', 'Members', 'Score', 'Users', 'Rank', 'Popularity', 'Description', 'Related', 'Characters', 'Voices', 'Staff']\n",
    ").T\n",
    "df = pd.concat([df, dftr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Type</th>\n",
       "      <th>Episodes</th>\n",
       "      <th>Release date</th>\n",
       "      <th>End date</th>\n",
       "      <th>Members</th>\n",
       "      <th>Score</th>\n",
       "      <th>Users</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Description</th>\n",
       "      <th>Related</th>\n",
       "      <th>Characters</th>\n",
       "      <th>Voices</th>\n",
       "      <th>Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>2010-07-04 00:00:00</td>\n",
       "      <td>2676639</td>\n",
       "      <td>9.16</td>\n",
       "      <td>1622384</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[\"After a horrific alchemy experiment goes wro...</td>\n",
       "      <td>['Adaptation: Fullmetal Alchemist', 'Alternati...</td>\n",
       "      <td>['Elric, Edward', 'Elric, Alphonse', 'Mustang,...</td>\n",
       "      <td>['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...</td>\n",
       "      <td>[['Cook, Justin', 'Producer'], ['Yonai, Norito...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gintama: The Final</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>-</td>\n",
       "      <td>79486</td>\n",
       "      <td>9.00</td>\n",
       "      <td>29979</td>\n",
       "      <td>10</td>\n",
       "      <td>1924</td>\n",
       "      <td>['New ', &lt;i&gt;Gintama&lt;/i&gt;, ' movie.']</td>\n",
       "      <td>['Adaptation: Gintama', 'Prequel: Gintama.: Sh...</td>\n",
       "      <td>['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...</td>\n",
       "      <td>['Sugita, Tomokazu', 'Ishida, Akira', 'Hino, S...</td>\n",
       "      <td>[['Fujita, Youichi', 'Director'], ['Miyawaki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gintama.</td>\n",
       "      <td>TV</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>2017-03-27 00:00:00</td>\n",
       "      <td>246290</td>\n",
       "      <td>8.98</td>\n",
       "      <td>108581</td>\n",
       "      <td>11</td>\n",
       "      <td>726</td>\n",
       "      <td>[\"After joining the resistance against the bak...</td>\n",
       "      <td>['Adaptation: Gintama', 'Prequel: Gintama°', '...</td>\n",
       "      <td>['Sakata, Gintoki', 'Kagura', 'Katsura, Kotaro...</td>\n",
       "      <td>['Sugita, Tomokazu', 'Kugimiya, Rie', 'Ishida,...</td>\n",
       "      <td>[['Fujita, Youichi', 'Director'], ['Miyawaki, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-gatsu no Lion 2nd Season</td>\n",
       "      <td>TV</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>2018-03-31 00:00:00</td>\n",
       "      <td>324393</td>\n",
       "      <td>8.97</td>\n",
       "      <td>155163</td>\n",
       "      <td>12</td>\n",
       "      <td>529</td>\n",
       "      <td>['Now in his second year of high school, Rei K...</td>\n",
       "      <td>['Adaptation: 3-gatsu no Lion', 'Prequel: 3-ga...</td>\n",
       "      <td>['Kiriyama, Rei', 'Kawamoto, Hinata', 'Kawamot...</td>\n",
       "      <td>['Kawanishi, Kengo', 'Hanazawa, Kana', 'Kayano...</td>\n",
       "      <td>[['Shinbou, Akiyuki', 'Director, Series Compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Koe no Katachi</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-09-17</td>\n",
       "      <td>-</td>\n",
       "      <td>1780070</td>\n",
       "      <td>8.97</td>\n",
       "      <td>1208990</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>['As a wild youth, elementary school student S...</td>\n",
       "      <td>['Adaptation: Koe no Katachi', 'Other: Koe no ...</td>\n",
       "      <td>['Nishimiya, Shouko', 'Ishida, Shouya', 'Nishi...</td>\n",
       "      <td>['Hayami, Saori', 'Irino, Miyu', 'Yuuki, Aoi',...</td>\n",
       "      <td>[['Senami, Riri', 'Assistant Producer'], ['Yam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>McDull: Boluo You Wang Zi</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17246</td>\n",
       "      <td>15088</td>\n",
       "      <td>['McDull, Prince de la Bun is a 2004 animated ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['McBing', 'McDull']</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>McDull: Chuntian Huahua Zhonghua Bowuguan</td>\n",
       "      <td>TV</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006-05-01 00:00:00</td>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17247</td>\n",
       "      <td>15436</td>\n",
       "      <td>['Featuring McDull going through Chinese cultu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['McDull']</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>McDull: Fan Bao Qibing</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17248</td>\n",
       "      <td>17359</td>\n",
       "      <td>['The 6th animated McDull feature film (7th fi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['McDull']</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>McDull: Kuaile Di Tan</td>\n",
       "      <td>ONA</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17249</td>\n",
       "      <td>18650</td>\n",
       "      <td>['Educational animation about environmental pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>McDull: Niu Hua Che Specials</td>\n",
       "      <td>Special</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17250</td>\n",
       "      <td>18857</td>\n",
       "      <td>['No synopsis information has been added to th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title     Type  Episodes  \\\n",
       "0              Fullmetal Alchemist: Brotherhood       TV        64   \n",
       "1                            Gintama: The Final    Movie         1   \n",
       "2                                      Gintama.       TV        12   \n",
       "3                    3-gatsu no Lion 2nd Season       TV        22   \n",
       "4                                Koe no Katachi    Movie         1   \n",
       "...                                         ...      ...       ...   \n",
       "8995                  McDull: Boluo You Wang Zi    Movie         1   \n",
       "8996  McDull: Chuntian Huahua Zhonghua Bowuguan       TV         5   \n",
       "8997                     McDull: Fan Bao Qibing    Movie         1   \n",
       "8998                      McDull: Kuaile Di Tan      ONA        20   \n",
       "8999               McDull: Niu Hua Che Specials  Special         2   \n",
       "\n",
       "     Release date             End date  Members  Score    Users   Rank  \\\n",
       "0      2009-04-05  2010-07-04 00:00:00  2676639   9.16  1622384      1   \n",
       "1      2021-01-08                    -    79486   9.00    29979     10   \n",
       "2      2017-01-09  2017-03-27 00:00:00   246290   8.98   108581     11   \n",
       "3      2017-10-14  2018-03-31 00:00:00   324393   8.97   155163     12   \n",
       "4      2016-09-17                    -  1780070   8.97  1208990     13   \n",
       "...           ...                  ...      ...    ...      ...    ...   \n",
       "8995          NaN                    -      261    NaN        0  17246   \n",
       "8996          NaN  2006-05-01 00:00:00      238    NaN        0  17247   \n",
       "8997          NaN                    -      128    NaN        0  17248   \n",
       "8998          NaN                    ?       24    NaN        0  17249   \n",
       "8999          NaN                    ?       18    NaN        0  17250   \n",
       "\n",
       "      Popularity                                        Description  \\\n",
       "0              3  [\"After a horrific alchemy experiment goes wro...   \n",
       "1           1924                ['New ', <i>Gintama</i>, ' movie.']   \n",
       "2            726  [\"After joining the resistance against the bak...   \n",
       "3            529  ['Now in his second year of high school, Rei K...   \n",
       "4             23  ['As a wild youth, elementary school student S...   \n",
       "...          ...                                                ...   \n",
       "8995       15088  ['McDull, Prince de la Bun is a 2004 animated ...   \n",
       "8996       15436  ['Featuring McDull going through Chinese cultu...   \n",
       "8997       17359  ['The 6th animated McDull feature film (7th fi...   \n",
       "8998       18650  ['Educational animation about environmental pr...   \n",
       "8999       18857  ['No synopsis information has been added to th...   \n",
       "\n",
       "                                                Related  \\\n",
       "0     ['Adaptation: Fullmetal Alchemist', 'Alternati...   \n",
       "1     ['Adaptation: Gintama', 'Prequel: Gintama.: Sh...   \n",
       "2     ['Adaptation: Gintama', 'Prequel: Gintama°', '...   \n",
       "3     ['Adaptation: 3-gatsu no Lion', 'Prequel: 3-ga...   \n",
       "4     ['Adaptation: Koe no Katachi', 'Other: Koe no ...   \n",
       "...                                                 ...   \n",
       "8995                                                NaN   \n",
       "8996                                                NaN   \n",
       "8997                                                NaN   \n",
       "8998                                                NaN   \n",
       "8999                                                NaN   \n",
       "\n",
       "                                             Characters  \\\n",
       "0     ['Elric, Edward', 'Elric, Alphonse', 'Mustang,...   \n",
       "1     ['Sakata, Gintoki', 'Kagura', 'Shimura, Shinpa...   \n",
       "2     ['Sakata, Gintoki', 'Kagura', 'Katsura, Kotaro...   \n",
       "3     ['Kiriyama, Rei', 'Kawamoto, Hinata', 'Kawamot...   \n",
       "4     ['Nishimiya, Shouko', 'Ishida, Shouya', 'Nishi...   \n",
       "...                                                 ...   \n",
       "8995                               ['McBing', 'McDull']   \n",
       "8996                                         ['McDull']   \n",
       "8997                                         ['McDull']   \n",
       "8998                                                NaN   \n",
       "8999                                                NaN   \n",
       "\n",
       "                                                 Voices  \\\n",
       "0     ['Park, Romi', 'Kugimiya, Rie', 'Miki, Shinich...   \n",
       "1     ['Sugita, Tomokazu', 'Ishida, Akira', 'Hino, S...   \n",
       "2     ['Sugita, Tomokazu', 'Kugimiya, Rie', 'Ishida,...   \n",
       "3     ['Kawanishi, Kengo', 'Hanazawa, Kana', 'Kayano...   \n",
       "4     ['Hayami, Saori', 'Irino, Miyu', 'Yuuki, Aoi',...   \n",
       "...                                                 ...   \n",
       "8995                                                 []   \n",
       "8996                                                 []   \n",
       "8997                                                 []   \n",
       "8998                                                NaN   \n",
       "8999                                                NaN   \n",
       "\n",
       "                                                  Staff  \n",
       "0     [['Cook, Justin', 'Producer'], ['Yonai, Norito...  \n",
       "1     [['Fujita, Youichi', 'Director'], ['Miyawaki, ...  \n",
       "2     [['Fujita, Youichi', 'Director'], ['Miyawaki, ...  \n",
       "3     [['Shinbou, Akiyuki', 'Director, Series Compos...  \n",
       "4     [['Senami, Riri', 'Assistant Producer'], ['Yam...  \n",
       "...                                                 ...  \n",
       "8995                                                NaN  \n",
       "8996                                                NaN  \n",
       "8997                                                NaN  \n",
       "8998                                                NaN  \n",
       "8999                                                NaN  \n",
       "\n",
       "[9000 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each row I created a tsv file with the value of each anime \n",
    "for i in range(len(df)):\n",
    "    with open(folder2+'/anime_'+str(i)+'.tsv', 'wt') as file:\n",
    "        tsv_writer = csv.writer(file, delimiter='\\t')\n",
    "        tsv_writer.writerow([x for x in df.columns]) #the header row\n",
    "        tsv_writer.writerow(x for x in df.iloc[i]) #the value under each columns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
